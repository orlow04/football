import sys
import os

# --- BLOCO DE CORRE√á√ÉO DE IMPORTA√á√ÉO ---
# Pega o caminho absoluto da pasta onde ESTE script (visualize_agent.py) est√°
current_dir = os.path.dirname(os.path.abspath(__file__))
# Adiciona ao sys.path
sys.path.append(current_dir)

print(f"Diret√≥rio de trabalho: {os.getcwd()}")
print(f"Caminho do script: {current_dir}")
print(f"Arquivos na pasta submission: {os.listdir(os.path.join(current_dir, 'submission'))}")
# ---------------------------------------

import gfootball.env as football_env
import numpy as np

try:
    from submission.agent import agent_factory
    print("‚úÖ SUCESSO! Agente importado.")
except ImportError as e:
    print(f"\n‚ùå ERRO FATAL DE IMPORTA√á√ÉO: {e}")
    print("Verifique se existe um arquivo '__init__.py' (vazio) dentro da pasta submission.")
    exit(1)

# Configura√ß√µes de v√≠deo
video_path = os.path.join(os.getcwd(), 'videos_agent')

env = football_env.create_environment(
    env_name="5_vs_5", 
    

    stacked=False, 
    
    representation='simple115v2',
    logdir=video_path, 
    write_goal_dumps=False, 
    write_full_episode_dumps=True,  # Grava o jogo inteiro
    render=False,                   # No Docker, render=True costuma falhar. O v√≠deo √© salvo no disco.
    write_video=True,
    
    # Garante que controlamos os 5 jogadores (como no treino)
    number_of_left_players_agent_controls=5
)

print(f"Action Space: {env.action_space}")
print(f"Observation Space: {env.observation_space}")
print("--------------------------------")

# Inicializa seu Agente
# O environment config pode ser None para testes simples
agent = agent_factory(None, None)

print("üé• Iniciando partida de exibi√ß√£o...")
obs = env.reset()
steps = 0
total_reward = 0

while True:
    actions = []
    
    # CORRE√á√ÉO: Tratamento robusto para matrizes NumPy (5, 115)
    # Se for um array e tiver dimens√£o 5 no in√≠cio, √© multi-agent
    if hasattr(obs, 'shape') and obs.shape[0] == 5:
        # Itera sobre as 5 linhas da matriz (uma obs por jogador)
        for i in range(5):
            player_obs = obs[i] # Pega a vis√£o do jogador i
            action = agent.take_action(player_obs)
            actions.append(action)
            
    # Fallback: Se for lista (formato antigo de alguns envs)
    elif isinstance(obs, list) and len(obs) == 5:
        for player_obs in obs:
            action = agent.take_action(player_obs)
            actions.append(action)
            
    # Fallback 2: Single agent
    else:
        action = agent.take_action(obs)
        actions = [action]

    # Envia as 5 a√ß√µes para o ambiente
    obs, rew, done, info = env.step(actions)
    
    # Soma a recompensa (pega a do primeiro jogador ou soma se for lista)
    if isinstance(rew, (list, np.ndarray)):
        step_reward = rew[0] 
    else:
        step_reward = rew
        
    total_reward += step_reward
    
    steps += 1
    if steps % 100 == 0:
        print(f"Step {steps} | Score: {info.get('score', '0-0')} | Reward Acumulado: {total_reward:.2f}")
    
    if done:
        print(f"Fim de jogo! Resultado Final: {info.get('score', 'Unknown')}")
        break

env.close()
print(f"‚úÖ Jogo finalizado em {steps} passos.")
print(f"üìÇ Verifique os v√≠deos gerados na pasta: {video_path}")


