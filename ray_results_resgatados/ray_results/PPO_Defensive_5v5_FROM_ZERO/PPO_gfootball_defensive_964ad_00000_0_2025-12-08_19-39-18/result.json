{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"defensive_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4504912836916128, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.008118512178789736, "policy_loss": -0.009806357322343785, "vf_loss": 0.00022175265411844363, "vf_explained_var": 0.5159726901671942, "kl": 0.007330463202891785, "entropy": 2.9370096007223596, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.38853503184713, "num_grad_updates_lifetime": 2355.5, "diff_num_grad_updates_vs_sampler_policy": 2354.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 40000, "num_agent_steps_trained": 40000}, "sampler_results": {"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "num_faulty_episodes": 0, "connector_metrics": {}}, "episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "num_faulty_episodes": 0, "connector_metrics": {}, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 40000, "num_agent_steps_trained": 40000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 107.67224950714123, "num_env_steps_trained_throughput_per_sec": 107.67224950714123, "timesteps_total": 4000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 40000, "timers": {"training_iteration_time_ms": 37149.755, "sample_time_ms": 13098.416, "learn_time_ms": 24046.575, "learn_throughput": 166.344, "synch_weights_time_ms": 4.136}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 40000, "num_agent_steps_trained": 40000}, "done": false, "episodes_total": 0, "training_iteration": 1, "trial_id": "964ad_00000", "date": "2025-12-08_19-39-59", "timestamp": 1765222799, "time_this_iter_s": 37.15179491043091, "time_total_s": 37.15179491043091, "pid": 4875, "hostname": "5be016125046", "node_ip": "172.17.0.2", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "gfootball_defensive", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 2, "enable_connectors": true, "_env_to_module_connector": null, "_module_to_env_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "validate_workers_after_construction": true, "compress_observations": false, "sampler_perf_stats_ema_coef": null, "sample_async": -1, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function policy_mapping_fn at 0x706c9c347af0>", "policies_to_train": ["defensive_policy"], "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "custom_async_evaluation_function": null, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_enable_new_api_stack": false, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"defensive_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}], "opponent_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}]}, "callbacks": "<class '__main__.SelfPlayUpdateCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 2}, "time_since_restore": 37.15179491043091, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 4.348, "ram_util_percent": 20.037999999999997}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"defensive_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.47396756378328725, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.008785613929774245, "policy_loss": -0.010713061706050282, "vf_loss": 7.711380723246472e-06, "vf_explained_var": 0.5592572222722817, "kl": 0.00959868562894769, "entropy": 2.925166303083902, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.38853503184713, "num_grad_updates_lifetime": 7065.5, "diff_num_grad_updates_vs_sampler_policy": 2354.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "sampler_results": {"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "num_faulty_episodes": 0, "connector_metrics": {}}, "episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "num_faulty_episodes": 0, "connector_metrics": {}, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.08793393476309, "num_env_steps_trained_throughput_per_sec": 102.08793393476309, "timesteps_total": 8000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 38165.821, "sample_time_ms": 12882.363, "learn_time_ms": 25278.057, "learn_throughput": 158.24, "synch_weights_time_ms": 4.882}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "episodes_total": 0, "training_iteration": 2, "trial_id": "964ad_00000", "date": "2025-12-08_19-40-38", "timestamp": 1765222838, "time_this_iter_s": 39.18479800224304, "time_total_s": 76.33659291267395, "pid": 4875, "hostname": "5be016125046", "node_ip": "172.17.0.2", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "gfootball_defensive", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 2, "enable_connectors": true, "_env_to_module_connector": null, "_module_to_env_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "validate_workers_after_construction": true, "compress_observations": false, "sampler_perf_stats_ema_coef": null, "sample_async": -1, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function policy_mapping_fn at 0x706c9c347ee0>", "policies_to_train": ["defensive_policy"], "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "custom_async_evaluation_function": null, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_enable_new_api_stack": false, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"defensive_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}], "opponent_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}]}, "callbacks": "<class '__main__.SelfPlayUpdateCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 2}, "time_since_restore": 76.33659291267395, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 4.3875, "ram_util_percent": 20.48333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"defensive_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5090968350379583, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.007834059452422253, "policy_loss": -0.00952126268878769, "vf_loss": 1.098332637777822e-06, "vf_explained_var": 0.5790542027246673, "kl": 0.008430529201262924, "entropy": 2.912415740444402, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.38853503184713, "num_grad_updates_lifetime": 11775.5, "diff_num_grad_updates_vs_sampler_policy": 2354.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 120000, "num_agent_steps_trained": 120000}, "sampler_results": {"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "num_faulty_episodes": 0, "connector_metrics": {}}, "episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "num_faulty_episodes": 0, "connector_metrics": {}, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 120000, "num_agent_steps_trained": 120000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 111.2068029821228, "num_env_steps_trained_throughput_per_sec": 111.2068029821228, "timesteps_total": 12000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 120000, "timers": {"training_iteration_time_ms": 37433.547, "sample_time_ms": 12201.762, "learn_time_ms": 25226.629, "learn_throughput": 158.563, "synch_weights_time_ms": 4.636}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 120000, "num_agent_steps_trained": 120000}, "done": false, "episodes_total": 0, "training_iteration": 3, "trial_id": "964ad_00000", "date": "2025-12-08_19-41-14", "timestamp": 1765222874, "time_this_iter_s": 35.97105574607849, "time_total_s": 112.30764865875244, "pid": 4875, "hostname": "5be016125046", "node_ip": "172.17.0.2", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "gfootball_defensive", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 2, "enable_connectors": true, "_env_to_module_connector": null, "_module_to_env_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "validate_workers_after_construction": true, "compress_observations": false, "sampler_perf_stats_ema_coef": null, "sample_async": -1, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function policy_mapping_fn at 0x706c9c347700>", "policies_to_train": ["defensive_policy"], "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "custom_async_evaluation_function": null, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_enable_new_api_stack": false, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"defensive_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}], "opponent_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}]}, "callbacks": "<class '__main__.SelfPlayUpdateCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 2}, "time_since_restore": 112.30764865875244, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 4.367346938775511, "ram_util_percent": 20.669387755102044}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"defensive_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.37199229269017586, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.0067192901093515245, "policy_loss": -0.008252187509825275, "vf_loss": 9.74930989505066e-06, "vf_explained_var": 0.4252448358480085, "kl": 0.007615742911691544, "entropy": 2.9020577869091317, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.38853503184713, "num_grad_updates_lifetime": 16485.5, "diff_num_grad_updates_vs_sampler_policy": 2354.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "sampler_results": {"episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.00099999999978, "opponent_policy": 3.00099999999978}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -12.460080184688632, "mean_inference_ms": 1.1636484148978472, "mean_action_processing_ms": 0.5782518765831614, "mean_env_wait_ms": 22.37442996137829, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007963180541992188, "StateBufferConnector_ms": 0.0098496675491333, "ViewRequirementAgentConnector_ms": 0.16397535800933838}}, "episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episodes_this_iter": 4, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.00099999999978, "opponent_policy": 3.00099999999978}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -12.460080184688632, "mean_inference_ms": 1.1636484148978472, "mean_action_processing_ms": 0.5782518765831614, "mean_env_wait_ms": 22.37442996137829, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007963180541992188, "StateBufferConnector_ms": 0.0098496675491333, "ViewRequirementAgentConnector_ms": 0.16397535800933838}, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 108.9311660571818, "num_env_steps_trained_throughput_per_sec": 108.9311660571818, "timesteps_total": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 37255.265, "sample_time_ms": 11825.565, "learn_time_ms": 25424.872, "learn_throughput": 157.326, "synch_weights_time_ms": 4.305}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "episodes_total": 4, "training_iteration": 4, "trial_id": "964ad_00000", "date": "2025-12-08_19-41-51", "timestamp": 1765222911, "time_this_iter_s": 36.72256541252136, "time_total_s": 149.0302140712738, "pid": 4875, "hostname": "5be016125046", "node_ip": "172.17.0.2", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "gfootball_defensive", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 2, "enable_connectors": true, "_env_to_module_connector": null, "_module_to_env_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "validate_workers_after_construction": true, "compress_observations": false, "sampler_perf_stats_ema_coef": null, "sample_async": -1, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function policy_mapping_fn at 0x706c9c3a9280>", "policies_to_train": ["defensive_policy"], "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "custom_async_evaluation_function": null, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_enable_new_api_stack": false, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"defensive_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}], "opponent_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}]}, "callbacks": "<class '__main__.SelfPlayUpdateCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 2}, "time_since_restore": 149.0302140712738, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 4.511764705882352, "ram_util_percent": 20.74117647058823}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"defensive_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6298695660004444, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.011539006886327533, "policy_loss": -0.013829376208526725, "vf_loss": 1.1343908890359942e-07, "vf_explained_var": 0.9087801289406552, "kl": 0.011451294244537669, "entropy": 2.8959820634493654, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.38853503184713, "num_grad_updates_lifetime": 21195.5, "diff_num_grad_updates_vs_sampler_policy": 2354.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 200000, "num_agent_steps_trained": 200000}, "sampler_results": {"episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.00099999999978, "opponent_policy": 3.00099999999978}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -12.460080184688632, "mean_inference_ms": 1.1636484148978472, "mean_action_processing_ms": 0.5782518765831614, "mean_env_wait_ms": 22.37442996137829, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007963180541992188, "StateBufferConnector_ms": 0.0098496675491333, "ViewRequirementAgentConnector_ms": 0.16397535800933838}}, "episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episodes_this_iter": 0, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.00099999999978, "opponent_policy": 3.00099999999978}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -12.460080184688632, "mean_inference_ms": 1.1636484148978472, "mean_action_processing_ms": 0.5782518765831614, "mean_env_wait_ms": 22.37442996137829, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007963180541992188, "StateBufferConnector_ms": 0.0098496675491333, "ViewRequirementAgentConnector_ms": 0.16397535800933838}, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 200000, "num_agent_steps_trained": 200000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 104.23281547494126, "num_env_steps_trained_throughput_per_sec": 104.23281547494126, "timesteps_total": 20000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 200000, "timers": {"training_iteration_time_ms": 37479.334, "sample_time_ms": 11655.782, "learn_time_ms": 25818.965, "learn_throughput": 154.925, "synch_weights_time_ms": 4.112}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 200000, "num_agent_steps_trained": 200000}, "done": false, "episodes_total": 4, "training_iteration": 5, "trial_id": "964ad_00000", "date": "2025-12-08_19-42-30", "timestamp": 1765222950, "time_this_iter_s": 38.377898931503296, "time_total_s": 187.4081130027771, "pid": 4875, "hostname": "5be016125046", "node_ip": "172.17.0.2", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "gfootball_defensive", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 2, "enable_connectors": true, "_env_to_module_connector": null, "_module_to_env_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "validate_workers_after_construction": true, "compress_observations": false, "sampler_perf_stats_ema_coef": null, "sample_async": -1, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function policy_mapping_fn at 0x706c9c3a9e50>", "policies_to_train": ["defensive_policy"], "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "custom_async_evaluation_function": null, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_enable_new_api_stack": false, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"defensive_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}], "opponent_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}]}, "callbacks": "<class '__main__.SelfPlayUpdateCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 2}, "time_since_restore": 187.4081130027771, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 4.457407407407408, "ram_util_percent": 20.901851851851863}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"defensive_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6069758430091692, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.01329202201703589, "policy_loss": -0.016129913039786264, "vf_loss": 4.350266056703424e-08, "vf_explained_var": 0.9795828121103299, "kl": 0.014189256381618635, "entropy": 2.886020299937821, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.38853503184713, "num_grad_updates_lifetime": 25905.5, "diff_num_grad_updates_vs_sampler_policy": 2354.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "sampler_results": {"episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.00099999999978, "opponent_policy": 3.00099999999978}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -12.460080184688632, "mean_inference_ms": 1.1636484148978472, "mean_action_processing_ms": 0.5782518765831614, "mean_env_wait_ms": 22.37442996137829, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007963180541992188, "StateBufferConnector_ms": 0.0098496675491333, "ViewRequirementAgentConnector_ms": 0.16397535800933838}}, "episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episodes_this_iter": 0, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.00099999999978, "opponent_policy": 3.00099999999978}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -12.460080184688632, "mean_inference_ms": 1.1636484148978472, "mean_action_processing_ms": 0.5782518765831614, "mean_env_wait_ms": 22.37442996137829, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007963180541992188, "StateBufferConnector_ms": 0.0098496675491333, "ViewRequirementAgentConnector_ms": 0.16397535800933838}, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 96.32261225995556, "num_env_steps_trained_throughput_per_sec": 96.32261225995556, "timesteps_total": 24000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 38153.96, "sample_time_ms": 11955.594, "learn_time_ms": 26193.372, "learn_throughput": 152.71, "synch_weights_time_ms": 4.481}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "episodes_total": 4, "training_iteration": 6, "trial_id": "964ad_00000", "date": "2025-12-08_19-43-11", "timestamp": 1765222991, "time_this_iter_s": 41.52951145172119, "time_total_s": 228.9376244544983, "pid": 4875, "hostname": "5be016125046", "node_ip": "172.17.0.2", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "gfootball_defensive", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 2, "enable_connectors": true, "_env_to_module_connector": null, "_module_to_env_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "validate_workers_after_construction": true, "compress_observations": false, "sampler_perf_stats_ema_coef": null, "sample_async": -1, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function policy_mapping_fn at 0x706c9c3d05e0>", "policies_to_train": ["defensive_policy"], "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "custom_async_evaluation_function": null, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_enable_new_api_stack": false, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"defensive_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}], "opponent_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}]}, "callbacks": "<class '__main__.SelfPlayUpdateCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 2}, "time_since_restore": 228.9376244544983, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 4.626315789473685, "ram_util_percent": 20.900000000000002}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"defensive_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2579102092978175, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.007956899251396355, "policy_loss": -0.009963672515499206, "vf_loss": 1.659578241955698e-05, "vf_explained_var": -0.006728675714723623, "kl": 0.009950888074023317, "entropy": 2.8539220303739965, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.38853503184713, "num_grad_updates_lifetime": 30615.5, "diff_num_grad_updates_vs_sampler_policy": 2354.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 280000, "num_agent_steps_trained": 280000}, "sampler_results": {"episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -5.224403560219157, "mean_inference_ms": 5.364325955526726, "mean_action_processing_ms": 0.5908494263488244, "mean_env_wait_ms": 10.898139221946241, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007900595664978027, "StateBufferConnector_ms": 0.009562075138092041, "ViewRequirementAgentConnector_ms": 0.1720905303955078}}, "episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episodes_this_iter": 4, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -5.224403560219157, "mean_inference_ms": 5.364325955526726, "mean_action_processing_ms": 0.5908494263488244, "mean_env_wait_ms": 10.898139221946241, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007900595664978027, "StateBufferConnector_ms": 0.009562075138092041, "ViewRequirementAgentConnector_ms": 0.1720905303955078}, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 280000, "num_agent_steps_trained": 280000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 99.77368548449358, "num_env_steps_trained_throughput_per_sec": 99.77368548449358, "timesteps_total": 28000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 280000, "timers": {"training_iteration_time_ms": 38430.634, "sample_time_ms": 11761.362, "learn_time_ms": 26664.469, "learn_throughput": 150.012, "synch_weights_time_ms": 4.3}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 280000, "num_agent_steps_trained": 280000}, "done": false, "episodes_total": 8, "training_iteration": 7, "trial_id": "964ad_00000", "date": "2025-12-08_19-43-51", "timestamp": 1765223031, "time_this_iter_s": 40.09243106842041, "time_total_s": 269.0300555229187, "pid": 4875, "hostname": "5be016125046", "node_ip": "172.17.0.2", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "gfootball_defensive", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 2, "enable_connectors": true, "_env_to_module_connector": null, "_module_to_env_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "validate_workers_after_construction": true, "compress_observations": false, "sampler_perf_stats_ema_coef": null, "sample_async": -1, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function policy_mapping_fn at 0x706c9c398a60>", "policies_to_train": ["defensive_policy"], "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "custom_async_evaluation_function": null, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_enable_new_api_stack": false, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"defensive_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}], "opponent_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}]}, "callbacks": "<class '__main__.SelfPlayUpdateCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 2}, "time_since_restore": 269.0300555229187, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 4.569811320754717, "ram_util_percent": 20.90000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"defensive_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6509740063465831, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.008998566790807185, "policy_loss": -0.011294091050167055, "vf_loss": 3.4291861882738736e-07, "vf_explained_var": 0.8830754874491641, "kl": 0.011475917376766127, "entropy": 2.8496594249822533, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.38853503184713, "num_grad_updates_lifetime": 35325.5, "diff_num_grad_updates_vs_sampler_policy": 2354.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "sampler_results": {"episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -5.224403560219157, "mean_inference_ms": 5.364325955526726, "mean_action_processing_ms": 0.5908494263488244, "mean_env_wait_ms": 10.898139221946241, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007900595664978027, "StateBufferConnector_ms": 0.009562075138092041, "ViewRequirementAgentConnector_ms": 0.1720905303955078}}, "episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episodes_this_iter": 0, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -5.224403560219157, "mean_inference_ms": 5.364325955526726, "mean_action_processing_ms": 0.5908494263488244, "mean_env_wait_ms": 10.898139221946241, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007900595664978027, "StateBufferConnector_ms": 0.009562075138092041, "ViewRequirementAgentConnector_ms": 0.1720905303955078}, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 107.3953507968886, "num_env_steps_trained_throughput_per_sec": 107.3953507968886, "timesteps_total": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 38282.498, "sample_time_ms": 11596.349, "learn_time_ms": 26681.443, "learn_throughput": 149.917, "synch_weights_time_ms": 4.23}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "episodes_total": 8, "training_iteration": 8, "trial_id": "964ad_00000", "date": "2025-12-08_19-44-28", "timestamp": 1765223068, "time_this_iter_s": 37.24818420410156, "time_total_s": 306.27823972702026, "pid": 4875, "hostname": "5be016125046", "node_ip": "172.17.0.2", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "gfootball_defensive", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 2, "enable_connectors": true, "_env_to_module_connector": null, "_module_to_env_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "validate_workers_after_construction": true, "compress_observations": false, "sampler_perf_stats_ema_coef": null, "sample_async": -1, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function policy_mapping_fn at 0x706c9c30fa60>", "policies_to_train": ["defensive_policy"], "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "custom_async_evaluation_function": null, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_enable_new_api_stack": false, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"defensive_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}], "opponent_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}]}, "callbacks": "<class '__main__.SelfPlayUpdateCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 2}, "time_since_restore": 306.27823972702026, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 4.508163265306122, "ram_util_percent": 20.96938775510204}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"defensive_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.688145755702776, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.01449165239403936, "policy_loss": -0.017192601107234914, "vf_loss": 3.7896492527401255e-08, "vf_explained_var": 0.9764725066167786, "kl": 0.013504573743360405, "entropy": 2.8400979485987605, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.38853503184713, "num_grad_updates_lifetime": 40035.5, "diff_num_grad_updates_vs_sampler_policy": 2354.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 360000, "num_agent_steps_trained": 360000}, "sampler_results": {"episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -5.224403560219157, "mean_inference_ms": 5.364325955526726, "mean_action_processing_ms": 0.5908494263488244, "mean_env_wait_ms": 10.898139221946241, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007900595664978027, "StateBufferConnector_ms": 0.009562075138092041, "ViewRequirementAgentConnector_ms": 0.1720905303955078}}, "episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episodes_this_iter": 0, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -5.224403560219157, "mean_inference_ms": 5.364325955526726, "mean_action_processing_ms": 0.5908494263488244, "mean_env_wait_ms": 10.898139221946241, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007900595664978027, "StateBufferConnector_ms": 0.009562075138092041, "ViewRequirementAgentConnector_ms": 0.1720905303955078}, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 360000, "num_agent_steps_trained": 360000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 105.28920545936423, "num_env_steps_trained_throughput_per_sec": 105.28920545936423, "timesteps_total": 36000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 360000, "timers": {"training_iteration_time_ms": 38250.062, "sample_time_ms": 11489.561, "learn_time_ms": 26755.889, "learn_throughput": 149.5, "synch_weights_time_ms": 4.119}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 360000, "num_agent_steps_trained": 360000}, "done": false, "episodes_total": 8, "training_iteration": 9, "trial_id": "964ad_00000", "date": "2025-12-08_19-45-06", "timestamp": 1765223106, "time_this_iter_s": 37.99250841140747, "time_total_s": 344.27074813842773, "pid": 4875, "hostname": "5be016125046", "node_ip": "172.17.0.2", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "gfootball_defensive", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 2, "enable_connectors": true, "_env_to_module_connector": null, "_module_to_env_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "validate_workers_after_construction": true, "compress_observations": false, "sampler_perf_stats_ema_coef": null, "sample_async": -1, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function policy_mapping_fn at 0x706c9c3a9820>", "policies_to_train": ["defensive_policy"], "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "custom_async_evaluation_function": null, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_enable_new_api_stack": false, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"defensive_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}], "opponent_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}]}, "callbacks": "<class '__main__.SelfPlayUpdateCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 2}, "time_since_restore": 344.27074813842773, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 4.474, "ram_util_percent": 21.0}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"defensive_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2598442002672172, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.01007801464930841, "policy_loss": -0.01208951017580088, "vf_loss": 2.3426771447085706e-05, "vf_explained_var": -0.5107751977038738, "kl": 0.009940343619348226, "entropy": 2.848544848344888, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.38853503184713, "num_grad_updates_lifetime": 44745.5, "diff_num_grad_updates_vs_sampler_policy": 2354.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "sampler_results": {"episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.00099999999978, "opponent_policy": 3.00099999999978}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -2.831087753377473, "mean_inference_ms": 5.929996163520261, "mean_action_processing_ms": 0.592665892347554, "mean_env_wait_ms": 7.81539891453104, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0069846709569295245, "StateBufferConnector_ms": 0.009287397066752115, "ViewRequirementAgentConnector_ms": 0.1753727595011393}}, "episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episodes_this_iter": 4, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.00099999999978, "opponent_policy": 3.00099999999978}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -2.831087753377473, "mean_inference_ms": 5.929996163520261, "mean_action_processing_ms": 0.592665892347554, "mean_env_wait_ms": 7.81539891453104, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0069846709569295245, "StateBufferConnector_ms": 0.009287397066752115, "ViewRequirementAgentConnector_ms": 0.1753727595011393}, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 98.5451800896588, "num_env_steps_trained_throughput_per_sec": 98.5451800896588, "timesteps_total": 40000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 400000, "timers": {"training_iteration_time_ms": 38484.106, "sample_time_ms": 11435.743, "learn_time_ms": 27043.698, "learn_throughput": 147.909, "synch_weights_time_ms": 4.123}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "done": false, "episodes_total": 12, "training_iteration": 10, "trial_id": "964ad_00000", "date": "2025-12-08_19-45-47", "timestamp": 1765223147, "time_this_iter_s": 40.592101097106934, "time_total_s": 384.86284923553467, "pid": 4875, "hostname": "5be016125046", "node_ip": "172.17.0.2", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "gfootball_defensive", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 2, "enable_connectors": true, "_env_to_module_connector": null, "_module_to_env_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "validate_workers_after_construction": true, "compress_observations": false, "sampler_perf_stats_ema_coef": null, "sample_async": -1, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function policy_mapping_fn at 0x706c9c3741f0>", "policies_to_train": ["defensive_policy"], "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "custom_async_evaluation_function": null, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_enable_new_api_stack": false, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"defensive_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}], "opponent_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}]}, "callbacks": "<class '__main__.SelfPlayUpdateCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 2}, "time_since_restore": 384.86284923553467, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 4.542592592592592, "ram_util_percent": 20.872222222222234}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"defensive_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7254880890345118, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.010659137769377812, "policy_loss": -0.012960190770232105, "vf_loss": 7.729037788069993e-07, "vf_explained_var": 0.7108250081286056, "kl": 0.011501408288751562, "entropy": 2.8216857860548985, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.38853503184713, "num_grad_updates_lifetime": 49455.5, "diff_num_grad_updates_vs_sampler_policy": 2354.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 440000, "num_agent_steps_trained": 440000}, "sampler_results": {"episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.00099999999978, "opponent_policy": 3.00099999999978}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -2.831087753377473, "mean_inference_ms": 5.929996163520261, "mean_action_processing_ms": 0.592665892347554, "mean_env_wait_ms": 7.81539891453104, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0069846709569295245, "StateBufferConnector_ms": 0.009287397066752115, "ViewRequirementAgentConnector_ms": 0.1753727595011393}}, "episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episodes_this_iter": 0, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.00099999999978, "opponent_policy": 3.00099999999978}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -2.831087753377473, "mean_inference_ms": 5.929996163520261, "mean_action_processing_ms": 0.592665892347554, "mean_env_wait_ms": 7.81539891453104, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0069846709569295245, "StateBufferConnector_ms": 0.009287397066752115, "ViewRequirementAgentConnector_ms": 0.1753727595011393}, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 440000, "num_agent_steps_trained": 440000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 97.33071979610575, "num_env_steps_trained_throughput_per_sec": 97.33071979610575, "timesteps_total": 44000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 440000, "timers": {"training_iteration_time_ms": 38878.827, "sample_time_ms": 11451.163, "learn_time_ms": 27422.989, "learn_throughput": 145.863, "synch_weights_time_ms": 4.163}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 440000, "num_agent_steps_trained": 440000}, "done": false, "episodes_total": 12, "training_iteration": 11, "trial_id": "964ad_00000", "date": "2025-12-08_19-46-28", "timestamp": 1765223188, "time_this_iter_s": 41.09984517097473, "time_total_s": 425.9626944065094, "pid": 4875, "hostname": "5be016125046", "node_ip": "172.17.0.2", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "gfootball_defensive", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 2, "enable_connectors": true, "_env_to_module_connector": null, "_module_to_env_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "validate_workers_after_construction": true, "compress_observations": false, "sampler_perf_stats_ema_coef": null, "sample_async": -1, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function policy_mapping_fn at 0x706c9c3a54c0>", "policies_to_train": ["defensive_policy"], "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "custom_async_evaluation_function": null, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_enable_new_api_stack": false, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"defensive_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}], "opponent_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}]}, "callbacks": "<class '__main__.SelfPlayUpdateCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 2}, "time_since_restore": 425.9626944065094, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 4.796428571428572, "ram_util_percent": 20.95892857142857}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"defensive_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7614594580451395, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.011820494753828632, "policy_loss": -0.014374274368775562, "vf_loss": 1.309532453343799e-07, "vf_explained_var": 0.9122987933472716, "kl": 0.012768260363345696, "entropy": 2.801433217702651, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.38853503184713, "num_grad_updates_lifetime": 54165.5, "diff_num_grad_updates_vs_sampler_policy": 2354.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "sampler_results": {"episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.00099999999978, "opponent_policy": 3.00099999999978}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -2.831087753377473, "mean_inference_ms": 5.929996163520261, "mean_action_processing_ms": 0.592665892347554, "mean_env_wait_ms": 7.81539891453104, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0069846709569295245, "StateBufferConnector_ms": 0.009287397066752115, "ViewRequirementAgentConnector_ms": 0.1753727595011393}}, "episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episodes_this_iter": 0, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.00099999999978, "opponent_policy": 3.00099999999978}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -2.831087753377473, "mean_inference_ms": 5.929996163520261, "mean_action_processing_ms": 0.592665892347554, "mean_env_wait_ms": 7.81539891453104, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0069846709569295245, "StateBufferConnector_ms": 0.009287397066752115, "ViewRequirementAgentConnector_ms": 0.1753727595011393}, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 97.60046099262539, "num_env_steps_trained_throughput_per_sec": 97.60046099262539, "timesteps_total": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 480000, "timers": {"training_iteration_time_ms": 39058.978, "sample_time_ms": 11341.066, "learn_time_ms": 27713.409, "learn_throughput": 144.334, "synch_weights_time_ms": 3.998}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "done": false, "episodes_total": 12, "training_iteration": 12, "trial_id": "964ad_00000", "date": "2025-12-08_19-47-09", "timestamp": 1765223229, "time_this_iter_s": 40.986427307128906, "time_total_s": 466.9491217136383, "pid": 4875, "hostname": "5be016125046", "node_ip": "172.17.0.2", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "gfootball_defensive", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 2, "enable_connectors": true, "_env_to_module_connector": null, "_module_to_env_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "validate_workers_after_construction": true, "compress_observations": false, "sampler_perf_stats_ema_coef": null, "sample_async": -1, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function policy_mapping_fn at 0x706c9c3a5dc0>", "policies_to_train": ["defensive_policy"], "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "custom_async_evaluation_function": null, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_enable_new_api_stack": false, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"defensive_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}], "opponent_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}]}, "callbacks": "<class '__main__.SelfPlayUpdateCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 2}, "time_since_restore": 466.9491217136383, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 4.453448275862069, "ram_util_percent": 20.929310344827588}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"defensive_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3299772753686725, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.011338692438549455, "policy_loss": -0.013482303536969638, "vf_loss": 2.5037921691007087e-05, "vf_explained_var": -0.40368567898774604, "kl": 0.010592866343090535, "entropy": 2.7913387160392324, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.38853503184713, "num_grad_updates_lifetime": 58875.5, "diff_num_grad_updates_vs_sampler_policy": 2354.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 520000, "num_agent_steps_trained": 520000}, "sampler_results": {"episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -1.633383707551481, "mean_inference_ms": 4.7730153030067495, "mean_action_processing_ms": 0.5960214315790866, "mean_env_wait_ms": 7.735723891120065, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00646635890007019, "StateBufferConnector_ms": 0.009343773126602173, "ViewRequirementAgentConnector_ms": 0.17722547054290771}}, "episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episodes_this_iter": 4, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -1.633383707551481, "mean_inference_ms": 4.7730153030067495, "mean_action_processing_ms": 0.5960214315790866, "mean_env_wait_ms": 7.735723891120065, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00646635890007019, "StateBufferConnector_ms": 0.009343773126602173, "ViewRequirementAgentConnector_ms": 0.17722547054290771}, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 520000, "num_agent_steps_trained": 520000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 96.97016552467565, "num_env_steps_trained_throughput_per_sec": 96.97016552467565, "timesteps_total": 52000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 520000, "timers": {"training_iteration_time_ms": 39587.056, "sample_time_ms": 11367.133, "learn_time_ms": 28215.548, "learn_throughput": 141.766, "synch_weights_time_ms": 3.891}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 520000, "num_agent_steps_trained": 520000}, "done": false, "episodes_total": 16, "training_iteration": 13, "trial_id": "964ad_00000", "date": "2025-12-08_19-47-51", "timestamp": 1765223271, "time_this_iter_s": 41.251869916915894, "time_total_s": 508.2009916305542, "pid": 4875, "hostname": "5be016125046", "node_ip": "172.17.0.2", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "gfootball_defensive", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 2, "enable_connectors": true, "_env_to_module_connector": null, "_module_to_env_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "validate_workers_after_construction": true, "compress_observations": false, "sampler_perf_stats_ema_coef": null, "sample_async": -1, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function policy_mapping_fn at 0x706c9c30fc10>", "policies_to_train": ["defensive_policy"], "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "custom_async_evaluation_function": null, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_enable_new_api_stack": false, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"defensive_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}], "opponent_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}]}, "callbacks": "<class '__main__.SelfPlayUpdateCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 2}, "time_since_restore": 508.2009916305542, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 4.466666666666667, "ram_util_percent": 20.87368421052632}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"defensive_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.792679562721789, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.012618596297085696, "policy_loss": -0.015458226960741632, "vf_loss": 1.1990418055826744e-06, "vf_explained_var": 0.7532029567756977, "kl": 0.014192165618869436, "entropy": 2.767739927996496, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.38853503184713, "num_grad_updates_lifetime": 63585.5, "diff_num_grad_updates_vs_sampler_policy": 2354.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "sampler_results": {"episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -1.633383707551481, "mean_inference_ms": 4.7730153030067495, "mean_action_processing_ms": 0.5960214315790866, "mean_env_wait_ms": 7.735723891120065, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00646635890007019, "StateBufferConnector_ms": 0.009343773126602173, "ViewRequirementAgentConnector_ms": 0.17722547054290771}}, "episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episodes_this_iter": 0, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -1.633383707551481, "mean_inference_ms": 4.7730153030067495, "mean_action_processing_ms": 0.5960214315790866, "mean_env_wait_ms": 7.735723891120065, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00646635890007019, "StateBufferConnector_ms": 0.009343773126602173, "ViewRequirementAgentConnector_ms": 0.17722547054290771}, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 89.3750190912321, "num_env_steps_trained_throughput_per_sec": 89.3750190912321, "timesteps_total": 56000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 560000, "timers": {"training_iteration_time_ms": 40390.536, "sample_time_ms": 11550.799, "learn_time_ms": 28835.345, "learn_throughput": 138.719, "synch_weights_time_ms": 3.913}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "done": false, "episodes_total": 16, "training_iteration": 14, "trial_id": "964ad_00000", "date": "2025-12-08_19-48-35", "timestamp": 1765223315, "time_this_iter_s": 44.757529497146606, "time_total_s": 552.9585211277008, "pid": 4875, "hostname": "5be016125046", "node_ip": "172.17.0.2", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "gfootball_defensive", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 2, "enable_connectors": true, "_env_to_module_connector": null, "_module_to_env_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "validate_workers_after_construction": true, "compress_observations": false, "sampler_perf_stats_ema_coef": null, "sample_async": -1, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function policy_mapping_fn at 0x706c9c335ca0>", "policies_to_train": ["defensive_policy"], "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "custom_async_evaluation_function": null, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_enable_new_api_stack": false, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"defensive_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}], "opponent_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}]}, "callbacks": "<class '__main__.SelfPlayUpdateCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 2}, "time_since_restore": 552.9585211277008, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 4.586440677966102, "ram_util_percent": 20.972881355932206}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"defensive_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8291357534832762, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.01199358514316811, "policy_loss": -0.014438031678485452, "vf_loss": 1.1731070867138612e-07, "vf_explained_var": 0.9113170370807566, "kl": 0.01222166210158472, "entropy": 2.727804141287591, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.38853503184713, "num_grad_updates_lifetime": 68295.5, "diff_num_grad_updates_vs_sampler_policy": 2354.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 600000, "num_agent_steps_trained": 600000}, "sampler_results": {"episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -1.633383707551481, "mean_inference_ms": 4.7730153030067495, "mean_action_processing_ms": 0.5960214315790866, "mean_env_wait_ms": 7.735723891120065, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00646635890007019, "StateBufferConnector_ms": 0.009343773126602173, "ViewRequirementAgentConnector_ms": 0.17722547054290771}}, "episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episodes_this_iter": 0, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -1.633383707551481, "mean_inference_ms": 4.7730153030067495, "mean_action_processing_ms": 0.5960214315790866, "mean_env_wait_ms": 7.735723891120065, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00646635890007019, "StateBufferConnector_ms": 0.009343773126602173, "ViewRequirementAgentConnector_ms": 0.17722547054290771}, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 600000, "num_agent_steps_trained": 600000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 100.04030122660997, "num_env_steps_trained_throughput_per_sec": 100.04030122660997, "timesteps_total": 60000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 600000, "timers": {"training_iteration_time_ms": 40551.361, "sample_time_ms": 11556.494, "learn_time_ms": 28990.414, "learn_throughput": 137.977, "synch_weights_time_ms": 3.942}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 600000, "num_agent_steps_trained": 600000}, "done": false, "episodes_total": 16, "training_iteration": 15, "trial_id": "964ad_00000", "date": "2025-12-08_19-49-15", "timestamp": 1765223355, "time_this_iter_s": 39.985679626464844, "time_total_s": 592.9442007541656, "pid": 4875, "hostname": "5be016125046", "node_ip": "172.17.0.2", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "gfootball_defensive", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 2, "enable_connectors": true, "_env_to_module_connector": null, "_module_to_env_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "validate_workers_after_construction": true, "compress_observations": false, "sampler_perf_stats_ema_coef": null, "sample_async": -1, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function policy_mapping_fn at 0x706c9c3d05e0>", "policies_to_train": ["defensive_policy"], "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "custom_async_evaluation_function": null, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_enable_new_api_stack": false, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"defensive_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}], "opponent_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}]}, "callbacks": "<class '__main__.SelfPlayUpdateCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 2}, "time_since_restore": 592.9442007541656, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 4.441509433962265, "ram_util_percent": 20.928301886792458}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"defensive_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.41321451566607204, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.010343470506324589, "policy_loss": -0.01293442549496383, "vf_loss": 3.750508237472707e-05, "vf_explained_var": -0.38842917297296464, "kl": 0.012767249391593202, "entropy": 2.73134533959083, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.38853503184713, "num_grad_updates_lifetime": 73005.5, "diff_num_grad_updates_vs_sampler_policy": 2354.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "sampler_results": {"episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.0100000000137, "episode_len_mean": 3001.0, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.0009999999997814, "opponent_policy": 3.0009999999997814}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -0.9136186197986227, "mean_inference_ms": 4.080947135692327, "mean_action_processing_ms": 0.5986527567915351, "mean_env_wait_ms": 7.694152802330761, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006298422813415527, "StateBufferConnector_ms": 0.00913381576538086, "ViewRequirementAgentConnector_ms": 0.1759195327758789}}, "episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.0100000000137, "episode_len_mean": 3001.0, "episodes_this_iter": 4, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.0009999999997814, "opponent_policy": 3.0009999999997814}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -0.9136186197986227, "mean_inference_ms": 4.080947135692327, "mean_action_processing_ms": 0.5986527567915351, "mean_env_wait_ms": 7.694152802330761, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006298422813415527, "StateBufferConnector_ms": 0.00913381576538086, "ViewRequirementAgentConnector_ms": 0.1759195327758789}, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 92.14603389177238, "num_env_steps_trained_throughput_per_sec": 92.14603389177238, "timesteps_total": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 640000, "timers": {"training_iteration_time_ms": 40739.586, "sample_time_ms": 11390.025, "learn_time_ms": 29345.541, "learn_throughput": 136.307, "synch_weights_time_ms": 3.544}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "done": false, "episodes_total": 20, "training_iteration": 16, "trial_id": "964ad_00000", "date": "2025-12-08_19-49-59", "timestamp": 1765223399, "time_this_iter_s": 43.41177940368652, "time_total_s": 636.3559801578522, "pid": 4875, "hostname": "5be016125046", "node_ip": "172.17.0.2", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "gfootball_defensive", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 2, "enable_connectors": true, "_env_to_module_connector": null, "_module_to_env_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "validate_workers_after_construction": true, "compress_observations": false, "sampler_perf_stats_ema_coef": null, "sample_async": -1, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function policy_mapping_fn at 0x706c9c347160>", "policies_to_train": ["defensive_policy"], "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "custom_async_evaluation_function": null, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_enable_new_api_stack": false, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"defensive_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}], "opponent_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}]}, "callbacks": "<class '__main__.SelfPlayUpdateCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 2}, "time_since_restore": 636.3559801578522, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 4.550877192982456, "ram_util_percent": 20.87192982456141}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"defensive_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8487204116620836, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.014667442590176206, "policy_loss": -0.017850732615597213, "vf_loss": 1.263683124617421e-06, "vf_explained_var": 0.6461268210233903, "kl": 0.01591013849595249, "entropy": 2.6866738484923247, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.38853503184713, "num_grad_updates_lifetime": 77715.5, "diff_num_grad_updates_vs_sampler_policy": 2354.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 680000, "num_agent_steps_trained": 680000}, "sampler_results": {"episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.0100000000137, "episode_len_mean": 3001.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.0009999999997814, "opponent_policy": 3.0009999999997814}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -0.9136186197986227, "mean_inference_ms": 4.080947135692327, "mean_action_processing_ms": 0.5986527567915351, "mean_env_wait_ms": 7.694152802330761, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006298422813415527, "StateBufferConnector_ms": 0.00913381576538086, "ViewRequirementAgentConnector_ms": 0.1759195327758789}}, "episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.0100000000137, "episode_len_mean": 3001.0, "episodes_this_iter": 0, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.0009999999997814, "opponent_policy": 3.0009999999997814}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -0.9136186197986227, "mean_inference_ms": 4.080947135692327, "mean_action_processing_ms": 0.5986527567915351, "mean_env_wait_ms": 7.694152802330761, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006298422813415527, "StateBufferConnector_ms": 0.00913381576538086, "ViewRequirementAgentConnector_ms": 0.1759195327758789}, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 680000, "num_agent_steps_trained": 680000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 91.26001814254306, "num_env_steps_trained_throughput_per_sec": 91.26001814254306, "timesteps_total": 68000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 680000, "timers": {"training_iteration_time_ms": 41113.596, "sample_time_ms": 11890.368, "learn_time_ms": 29219.057, "learn_throughput": 136.897, "synch_weights_time_ms": 3.693}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 680000, "num_agent_steps_trained": 680000}, "done": false, "episodes_total": 20, "training_iteration": 17, "trial_id": "964ad_00000", "date": "2025-12-08_19-50-43", "timestamp": 1765223443, "time_this_iter_s": 43.832988023757935, "time_total_s": 680.1889681816101, "pid": 4875, "hostname": "5be016125046", "node_ip": "172.17.0.2", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "gfootball_defensive", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 2, "enable_connectors": true, "_env_to_module_connector": null, "_module_to_env_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "validate_workers_after_construction": true, "compress_observations": false, "sampler_perf_stats_ema_coef": null, "sample_async": -1, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function policy_mapping_fn at 0x706cbd405dc0>", "policies_to_train": ["defensive_policy"], "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "custom_async_evaluation_function": null, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_enable_new_api_stack": false, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"defensive_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}], "opponent_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}]}, "callbacks": "<class '__main__.SelfPlayUpdateCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 2}, "time_since_restore": 680.1889681816101, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 4.577586206896552, "ram_util_percent": 20.96896551724138}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"defensive_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8989077929098894, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.012570151913968694, "policy_loss": -0.015129708901597405, "vf_loss": 1.6535868004452455e-07, "vf_explained_var": 0.8875156015980269, "kl": 0.012796972730393376, "entropy": 2.6598081561410503, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.38853503184713, "num_grad_updates_lifetime": 82425.5, "diff_num_grad_updates_vs_sampler_policy": 2354.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "sampler_results": {"episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.0100000000137, "episode_len_mean": 3001.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.0009999999997814, "opponent_policy": 3.0009999999997814}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -0.9136186197986227, "mean_inference_ms": 4.080947135692327, "mean_action_processing_ms": 0.5986527567915351, "mean_env_wait_ms": 7.694152802330761, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006298422813415527, "StateBufferConnector_ms": 0.00913381576538086, "ViewRequirementAgentConnector_ms": 0.1759195327758789}}, "episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.0100000000137, "episode_len_mean": 3001.0, "episodes_this_iter": 0, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.0009999999997814, "opponent_policy": 3.0009999999997814}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": -0.9136186197986227, "mean_inference_ms": 4.080947135692327, "mean_action_processing_ms": 0.5986527567915351, "mean_env_wait_ms": 7.694152802330761, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006298422813415527, "StateBufferConnector_ms": 0.00913381576538086, "ViewRequirementAgentConnector_ms": 0.1759195327758789}, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 88.9263602960749, "num_env_steps_trained_throughput_per_sec": 88.9263602960749, "timesteps_total": 72000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 720000, "timers": {"training_iteration_time_ms": 41887.144, "sample_time_ms": 12130.318, "learn_time_ms": 29752.752, "learn_throughput": 134.441, "synch_weights_time_ms": 3.593}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "done": false, "episodes_total": 20, "training_iteration": 18, "trial_id": "964ad_00000", "date": "2025-12-08_19-51-28", "timestamp": 1765223488, "time_this_iter_s": 44.98296904563904, "time_total_s": 725.1719372272491, "pid": 4875, "hostname": "5be016125046", "node_ip": "172.17.0.2", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "gfootball_defensive", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 2, "enable_connectors": true, "_env_to_module_connector": null, "_module_to_env_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "validate_workers_after_construction": true, "compress_observations": false, "sampler_perf_stats_ema_coef": null, "sample_async": -1, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function policy_mapping_fn at 0x706c9c3131f0>", "policies_to_train": ["defensive_policy"], "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "custom_async_evaluation_function": null, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_enable_new_api_stack": false, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"defensive_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}], "opponent_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}]}, "callbacks": "<class '__main__.SelfPlayUpdateCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 2}, "time_since_restore": 725.1719372272491, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 4.514285714285713, "ram_util_percent": 21.0}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"defensive_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5552781842174423, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.013230327999460533, "policy_loss": -0.015645009125118202, "vf_loss": 2.331894598915194e-05, "vf_explained_var": -0.11469197697194013, "kl": 0.01195681064241393, "entropy": 2.6506724405693656, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.38853503184713, "num_grad_updates_lifetime": 87135.5, "diff_num_grad_updates_vs_sampler_policy": 2354.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 760000, "num_agent_steps_trained": 760000}, "sampler_results": {"episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.0009999999997796, "opponent_policy": 3.0009999999997796}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.07903827172309026, "mean_inference_ms": 3.6239573836701937, "mean_action_processing_ms": 0.6019906068029511, "mean_env_wait_ms": 7.19729086806835, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006485482056935628, "StateBufferConnector_ms": 0.009239216645558676, "ViewRequirementAgentConnector_ms": 0.17786622047424316}}, "episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episodes_this_iter": 4, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.0009999999997796, "opponent_policy": 3.0009999999997796}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.07903827172309026, "mean_inference_ms": 3.6239573836701937, "mean_action_processing_ms": 0.6019906068029511, "mean_env_wait_ms": 7.19729086806835, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006485482056935628, "StateBufferConnector_ms": 0.009239216645558676, "ViewRequirementAgentConnector_ms": 0.17786622047424316}, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 760000, "num_agent_steps_trained": 760000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 103.84640407781264, "num_env_steps_trained_throughput_per_sec": 103.84640407781264, "timesteps_total": 76000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 760000, "timers": {"training_iteration_time_ms": 41939.926, "sample_time_ms": 12265.699, "learn_time_ms": 29670.19, "learn_throughput": 134.815, "synch_weights_time_ms": 3.591}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 760000, "num_agent_steps_trained": 760000}, "done": false, "episodes_total": 24, "training_iteration": 19, "trial_id": "964ad_00000", "date": "2025-12-08_19-52-06", "timestamp": 1765223526, "time_this_iter_s": 38.52060270309448, "time_total_s": 763.6925399303436, "pid": 4875, "hostname": "5be016125046", "node_ip": "172.17.0.2", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "gfootball_defensive", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 2, "enable_connectors": true, "_env_to_module_connector": null, "_module_to_env_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "validate_workers_after_construction": true, "compress_observations": false, "sampler_perf_stats_ema_coef": null, "sample_async": -1, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function policy_mapping_fn at 0x706c9c313c10>", "policies_to_train": ["defensive_policy"], "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "custom_async_evaluation_function": null, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_enable_new_api_stack": false, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"defensive_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}], "opponent_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}]}, "callbacks": "<class '__main__.SelfPlayUpdateCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 2}, "time_since_restore": 763.6925399303436, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 4.527777777777779, "ram_util_percent": 20.887037037037043}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"defensive_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9176959934761063, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.011500080881270554, "policy_loss": -0.014262323184017954, "vf_loss": 1.9698368405508204e-06, "vf_explained_var": 0.5467741093944339, "kl": 0.01380136728797229, "entropy": 2.603893074969071, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.38853503184713, "num_grad_updates_lifetime": 91845.5, "diff_num_grad_updates_vs_sampler_policy": 2354.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "sampler_results": {"episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.0009999999997796, "opponent_policy": 3.0009999999997796}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.07903827172309026, "mean_inference_ms": 3.6239573836701937, "mean_action_processing_ms": 0.6019906068029511, "mean_env_wait_ms": 7.19729086806835, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006485482056935628, "StateBufferConnector_ms": 0.009239216645558676, "ViewRequirementAgentConnector_ms": 0.17786622047424316}}, "episode_reward_max": 30.010000000013694, "episode_reward_min": 30.010000000013694, "episode_reward_mean": 30.010000000013694, "episode_len_mean": 3001.0, "episodes_this_iter": 0, "policy_reward_min": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_max": {"defensive_policy": 3.0009999999997805, "opponent_policy": 3.0009999999997805}, "policy_reward_mean": {"defensive_policy": 3.0009999999997796, "opponent_policy": 3.0009999999997796}, "hist_stats": {"episode_reward": [30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694, 30.010000000013694], "episode_lengths": [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001], "policy_defensive_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805], "policy_opponent_policy_reward": [3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805, 3.0009999999997805]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.07903827172309026, "mean_inference_ms": 3.6239573836701937, "mean_action_processing_ms": 0.6019906068029511, "mean_env_wait_ms": 7.19729086806835, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006485482056935628, "StateBufferConnector_ms": 0.009239216645558676, "ViewRequirementAgentConnector_ms": 0.17786622047424316}, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 97.80481701264469, "num_env_steps_trained_throughput_per_sec": 97.80481701264469, "timesteps_total": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 800000, "timers": {"training_iteration_time_ms": 41970.652, "sample_time_ms": 12443.902, "learn_time_ms": 29522.847, "learn_throughput": 135.488, "synch_weights_time_ms": 3.505}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "done": false, "episodes_total": 24, "training_iteration": 20, "trial_id": "964ad_00000", "date": "2025-12-08_19-52-47", "timestamp": 1765223567, "time_this_iter_s": 40.89960551261902, "time_total_s": 804.5921454429626, "pid": 4875, "hostname": "5be016125046", "node_ip": "172.17.0.2", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "gfootball_defensive", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 2, "enable_connectors": true, "_env_to_module_connector": null, "_module_to_env_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "validate_workers_after_construction": true, "compress_observations": false, "sampler_perf_stats_ema_coef": null, "sample_async": -1, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function policy_mapping_fn at 0x706c9c3a59d0>", "policies_to_train": ["defensive_policy"], "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "custom_async_evaluation_function": null, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_enable_new_api_stack": false, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"defensive_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}], "opponent_policy": [null, "Box(-inf, inf, (115,), float32)", "Discrete(19)", {}]}, "callbacks": "<class '__main__.SelfPlayUpdateCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 2}, "time_since_restore": 804.5921454429626, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 4.551785714285714, "ram_util_percent": 20.97142857142857}}
